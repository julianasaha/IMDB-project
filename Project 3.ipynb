{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d93fea",
   "metadata": {},
   "source": [
    "# IMDB Project 3\n",
    "- Juliana Sahagun\n",
    "- 08/17/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "883d80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aab41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files\n",
    "basics_url= \"https://datasets.imdbws.com/title.basics.tsv.gz\"\n",
    "ratings_url= \"https://datasets.imdbws.com/title.basics.tsv.gz\"\n",
    "akas_url= \"https://datasets.imdbws.com/title.akas.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02f5a9b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_basics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(basics_url,sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m df_akas\u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43makas_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m df_ratings\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(ratings_url,sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1252\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:787\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:876\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "df_basics = pd.read_csv(basics_url,sep='\\t', low_memory=False)\n",
    "df_akas= pd.read_csv(akas_url, sep='\\t', low_memory=False)\n",
    "df_ratings= pd.read_csv(ratings_url,sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58fc7cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>short</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>4</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>short</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>short</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>0</td>\n",
       "      <td>1893</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy,Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType            primaryTitle           originalTitle  \\\n",
       "0  tt0000001     short              Carmencita              Carmencita   \n",
       "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       "2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
       "3  tt0000004     short             Un bon bock             Un bon bock   \n",
       "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       "\n",
       "  isAdult startYear endYear runtimeMinutes                    genres  \n",
       "0       0      1894      \\N              1         Documentary,Short  \n",
       "1       0      1892      \\N              5           Animation,Short  \n",
       "2       0      1892      \\N              4  Animation,Comedy,Romance  \n",
       "3       0      1892      \\N             12           Animation,Short  \n",
       "4       0      1893      \\N              1              Comedy,Short  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c03ced6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_ratings\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_ratings' is not defined"
     ]
    }
   ],
   "source": [
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d6b32a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_akas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_akas\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_akas' is not defined"
     ]
    }
   ],
   "source": [
    "df_akas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aea619",
   "metadata": {},
   "source": [
    "## Cleaning/Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a374afc",
   "metadata": {},
   "source": [
    "Basics Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74a7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"\\N\" with np.nan\n",
    "df_basics = df_basics.replace({'\\\\N':np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c20cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove movies having missing values for runtimeMinutes and genre\n",
    "df_basics= df_basics.dropna(subset=['runtimeMinutes','genres','startYear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462d22f",
   "metadata": {},
   "source": [
    "startYear also has null values that should be removed because it interferes with keep all movies with the start year 2000-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b1aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include only full-length movies (titleType = \"movie\")\n",
    "df_basics = df_basics.loc[df_basics['titleType']=='movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b3e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate movies that include \"Documentary\" in genre\n",
    "doc= df_basics['genres'].str.contains('documentary', case=False)\n",
    "df_basics = df_basics[~doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9481afb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Keep startYear 2000-2022\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_basics\u001b[38;5;241m=\u001b[39m df_basics\u001b[38;5;241m.\u001b[39mloc[(\u001b[43mdf_basics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstartYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m) \u001b[38;5;241m&\u001b[39m (df_basics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstartYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2021\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5620\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 5623\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:73\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     71\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\_libs\\ops.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# Keep startYear 2000-2022\n",
    "df_basics= df_basics.loc[(df_basics['startYear'] >=2000) & (df_basics['startYear'] <=2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5940c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basics.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab23273",
   "metadata": {},
   "source": [
    "Akas Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773013e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only movies that were released in the United States\n",
    "df_akas = df_akas.loc[df_akas['region']=='US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"\\N\" with np.nan\n",
    "df_akas=df_akas.replace({'\\\\N': np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_akas.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea7f3e",
   "metadata": {},
   "source": [
    "Ratings Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a42d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"\\N\" with np.nan\n",
    "df_ratings = df_ratings.replace({'\\\\N':np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering one dataframe based on another\n",
    "keepers = df_basics['tconst'].isin(df_akas['titleId'])\n",
    "df_basics =df_basics[keepers]\n",
    "df_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folders for data\n",
    "import os\n",
    "os.makedirs('Data/',exist_ok=True) \n",
    "\n",
    "# Confirm folder created\n",
    "os.listdir(\"Data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current dataframe to file\n",
    "df_basics.to_csv(\"Data/title_basics.csv.gz\",compression='gzip',index=False)\n",
    "df_akas.to_csv(\"Data/title_akas.csv.gz\",compression='gzip',index=False)\n",
    "df_ratings.to_csv(\"Data/title_ratings.csv.gz\",compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open saved file and preview again\n",
    "df_basics = pd.read_csv(\"Data/title_basics.csv.gz\", low_memory = False)\n",
    "df_basics.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce906225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings=pd.read_csv(\"Data/title_ratings.csv.gz\", low_memory =False)\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da03cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_akas=pd.read_csv(\"Data/title_akas.csv.gz\",low_memory=False)\n",
    "df_akas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516f4cd",
   "metadata": {},
   "source": [
    "PART TWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read file\n",
    "with open('/Users/julia/.secret/tmdb_api.json', 'r') as f:\n",
    "    login = json.load(f)\n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15561c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from the LP\n",
    "def get_movie_and_rating(movie_id):    \n",
    "    \n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    movie_info = movie.info()\n",
    "    releases = movie.releases()\n",
    "\n",
    "    for c in releases['countries']:\n",
    "        if c['iso_3166_1' ] =='US':\n",
    "            movie_info['certification'] = c['certification']\n",
    "    return movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d933c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_movie_and_rating(\"tt0848228\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_TO_GET =[2000,2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"    \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23600f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_fix_json(JSON_FILE):\n",
    "    \"\"\"Attempts to read in json file of records and fixes the final character\n",
    "    to end with a ] if it errors.\n",
    "    \n",
    "    Args:\n",
    "        JSON_FILE (str): filepath of JSON file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: the corrected data from the bad json file\n",
    "    \"\"\"\n",
    "    try: \n",
    "        previous_df =  pd.read_json(JSON_FILE)\n",
    "    \n",
    "    ## If read_json throws an error\n",
    "    except:\n",
    "        \n",
    "        ## manually open the json file\n",
    "        with open(JSON_FILE,'r+') as f:\n",
    "            ## Read in the file as a STRING\n",
    "            bad_json = f.read()\n",
    "            \n",
    "            ## if the final character doesn't match first, select the right bracket\n",
    "            first_char = bad_json[0]\n",
    "            final_brackets = {'[':']', \n",
    "                           \"{\":\"}\"}\n",
    "            ## Select expected final brakcet\n",
    "            final_char = final_brackets[first_char]\n",
    "            \n",
    "            ## if the last character in file doen't match the first char, add it\n",
    "            if bad_json[-1] != final_char:\n",
    "                good_json = bad_json[:-1]\n",
    "                good_json+=final_char\n",
    "            else:\n",
    "                raise Exception('ERROR is not due to mismatched final bracket.')\n",
    "            \n",
    "            ## Rewind to start of file and write new good_json to disk\n",
    "            f.seek(0)\n",
    "            f.write(good_json)\n",
    "           \n",
    "        ## Load the json file again now that its fixed\n",
    "        previous_df =  pd.read_json(JSON_FILE)\n",
    "        \n",
    "    return previous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Load the json file again now that its fixed\n",
    "        previous_df =  pd.read_json(JSON_FILE)\n",
    "        \n",
    "    return previous_df\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET,desc='YEARS',position=0):\n",
    "    \n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "    \n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    \n",
    "    if file_exists == False:\n",
    "            with open(JSON_FILE,'w') as f:\n",
    "                json.dump([{'imdb_id':0}],f)\n",
    "                basics = pd.read_csv(\"Data/title_basics.csv.gz\", low_memory = False)\n",
    "\n",
    "                df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "\n",
    "                movie_ids = df['tconst'].copy()\n",
    "\n",
    "                previous_df = read_and_fix_json(JSON_FILE)\n",
    "\n",
    "                movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n",
    "                for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                      desc=f'Movies from {YEAR}',\n",
    "                                      position=1,\n",
    "                                      leave=True):\n",
    "            # Attempt to retrieve then data for the movie id\n",
    "                    try:\n",
    "                        temp = get_movie_and_rating(movie_id)  #This uses your pre-made function\n",
    "                        # Append/extend results to existing file using a pre-made function\n",
    "                        write_json(temp,JSON_FILE)\n",
    "                        # Short 20 ms sleep to prevent overwhelming server\n",
    "                        time.sleep(0.02)\n",
    "\n",
    "                    # If it fails,  make a dict with just the id and None for certification.\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "\n",
    "                    final_year_df = pd.read_json(JSON_FILE)\n",
    "\n",
    "                    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\",\n",
    "                                         compression=\"gzip\", index=False)\n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
